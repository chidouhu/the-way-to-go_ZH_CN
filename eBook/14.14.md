#14.14 并发计算大数据集
假设我们要处理来自于一个输入channel的大量数据, 并全部传递给一个输出channel, 类似于一个工厂pipeline. 每个数据项的计算会牵扯到很多个步骤: Preprocess/StepA/StepB/ ... /PostProcess

一个通用的顺序pipelining算法可以用于解决每个步骤的执行:

	func SerialProcessData (in <- chan *Data, out <- chan *Data) {
		for data := range in {
			tmpA := PreprocessData(data)
			tmpB := PreprocessData(tmpA)
			tmpC := PreprocessData(tmpB)			
			out <- PostProcessData(tmpC)
		}
	}

一次只能执行一个步骤, 每个数据项都被顺序处理: 在第一个数据项完成处理并发送到输出channel之前第二个数据项不会开始.

一个更有效的计算是让处理步骤全部以goroutine方式隔离. 每个步骤从前一个步骤的输出channel取数据. 这种方法节省了大量的时间:

	func ParallelProcessData (in <- chan *Data, out <- chan *Data) {
		// make channels:
		preOut := make(chan *Data, 100)
		stepAOut := make(chan *Data, 100)
		stepBOut := make(chan *Data, 100)
		stepCOut := make(chan *Data, 100)
		// start parallel computations:
		go PreprocessData(in, preOut)
		go PreprocessData(preOut, stepAOut)
		go PreprocessData(stepAOut, stepBOut)
		go PreprocessData(stepBOut, stepCOut)
		go PostprocessData(stepCOut, out)
	}

channel的缓冲区容量可以用于优化整个进程.

##链接
- [目录](directory.md)
- 上一节：[](14.13.md)
- 下一节：[](14.15.md)