#14.7 对比新旧模式: Tasks和Worker进程
假设我们要计算大量的任务; 每个任务由一个worker(进程)完成. 每个任务可以用一个结构体来定义(具体细节这里不重要):

	type Task struct {
		// some state
	}

## 1. 使用共享内存来同步
任务池是共享内存的; 为了同步并且避免条件竞争, 我们必须用互斥锁来保护任务池:

	type Pool struct {
		Mu sync.Mutex
		Tasks []Task
	}

sync.Mutex(参见9.3)是一种互斥锁: 它用来保护关键代码区的入口: 同一时刻只有一个goroutine(线程)可以进入该区域. 如果允许多个goroutine进入, 就会存在条件竞争: Pool结构无法正确更新. 在传统模型中(应用于大部分传统语言如C++, Java, C#)worker进程的代码类似于:

	func Worker(pool *Pool) {
		for {
			pool.Mu.Lock()
			// begin critical section:
			task := pool.Tasks[0]		// take the first task
			pool.Tasks = pool.Tasks[1:]	// update the pool of tasks
			// end critical section
			pool.Mu.Unlock()
			process(task)
		}
	}

大部分工作进程都可以并行执行; 它们可以以goroutine的方式启动. 一个worker锁住pool, 从pool中拿走第一个任务, 将pool解锁, 然后处理这个任务. 锁保证了在同一时刻只有一个工作进程可以访问pool: 一个任务被且仅被分配给一个worker. 如果这里不加锁, worker处理逻辑中的代码task := pool.Tasks[0]和pool.Tasks = pool.Tasks[1:]可能会被打断: 某些worker可能取不到任务, 而某些任何可能会被多个worker获得. 锁同步机制在worker进程较少的时候很好用, 但是如果Pool很大时我们分配大量的进程来工作, 处理效率可能会被加锁解锁的代价影响. 瓶颈在于: 当工作worker增加时性能反而下降了, 并且在某个阈值大幅下降.

## 2. channels
现在任务channel就可以用来同步了: 一个pending channel接受请求任务, 一个done channel接受计算完成的任务和结果. worker进程以goroutine运行, 数目N取决于task的数目.

主循环的代码可以这么写:

	func main() {
		pending, done := make(chan *Task), make(chan *Task)
		go sendWork(pending)		// put tasks with work on the channel
		for i := 0; i < N; i++ {	// start N goroutines to work
			go Worker(pending, done)
		}
		consumeWork(done)			// continue with the processed tasks
	}

工作进程十分简单: 从pending channel取任务, 将完成的任务放入done channel:

	func Worker(in, out chan *Task) {
		for {
			t := <-in
			process(t)
			out <- t
		}
	}

整个过程没有锁: 获取新任务没有竞争. 如果任务数目上升, worker的数目也相应上升并且性能不会像方案1一样下降. pending channel会有一份内存拷贝, 但是不会有竞争, 因为第一个Worker取走了第一个task(从channel读和写都是原子操作: 参加章节14.2.2)并且完成了计算. 你无法判断某个任务会被哪个进程处理. 当worker数量上升时也会有通信代价, 但是对性能只有轻微的影响.

在这个简单的例子中可能不能完全看到方案2的优点, 但是用复杂的锁条件实现的应用很难编程并且正确运行, 在方案2中不会引入这样的复杂性.

因此, 不仅仅是为了提高性能, 清晰和优雅的代码也是一个较大的优点. 这是一个Go语言管用的方法:

	IDIOM: Use an in- and out-channel instead of locking
		func Worker(in, out chan *Task) {
			for {
				t := <-in
				process(t)
				out <- t
			}
		}

对于所有的类似Master-Worker结构的问题, 一个通用的方案就是Worker以goroutine运行并通过channel交互, Master作为协调. 如果系统分布在不同的机器上, 大量的机器可以执行Worker的goroutine, 而Master和Worker可以通过netchan或者rpc交互(参见章节15).

## 用哪个: sync.Mutex还是channel?
尽管本章我们强调了用goroutine通过channel交互的方法, 这不并意味着传统的使用锁的方法就是禁止的: Go允许你根据问题来选择: 更优雅,简单和可读的解决问题, 在大部分场景中性能优异. 不要害怕使用锁, 如果你的问题本身适合使用锁. Go语言是务实的, 它让你以最合适的方式解决问题而不是强迫你使用某一种风格的代码. 总体来说:

1. 在以下情况使用锁:
	1. 在共享数据结构中缓存信息
	2. 维护状态信息, 包括运行程序的上下文或者状态
2. 在以下情况使用channel:
	1. 交互异步结果
	2. 分布式执行单元
	3. 传递数据所有权

如果使用锁的方案过于复杂, 问问你自己是不是使用channel更简单.

	
##链接
- [目录](directory.md)
- 上一节：[在goroutine中使用recover](14.6.md)
- 下一节：[实现lazy生成器](14.8.md)